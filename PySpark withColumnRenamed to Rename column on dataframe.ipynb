{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d534634",
   "metadata": {},
   "source": [
    "# PySpark `withColumnRenamed()` \n",
    "            by Aishwarya Raut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68cf39fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:59:12.434950Z",
     "start_time": "2023-11-29T11:59:12.081302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SP').getOrCreate()\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fb694",
   "metadata": {},
   "source": [
    "# 1. PySpark withColumnRenamed – To rename DataFrame column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ccfc65",
   "metadata": {},
   "source": [
    "**PySpark withColumnRenamed() Syntax:**\n",
    "\n",
    "`withColumnRenamed(existingName, newNam)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cef82c3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:50:29.070028Z",
     "start_time": "2023-11-29T11:50:28.795720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab6db9d",
   "metadata": {},
   "source": [
    "# 2. PySpark withColumnRenamed – To rename multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86ce3a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:52:04.044739Z",
     "start_time": "2023-11-29T11:52:03.963471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.withColumnRenamed(\"dob\",\"DateOfBirth\").withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b375bff1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:59:19.972147Z",
     "start_time": "2023-11-29T11:59:19.914905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.withColumnsRenamed({\"dob\":\"DateOfBirth\",\"salary\":\"salary_amount\"})\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c450a3",
   "metadata": {},
   "source": [
    "# 3. Using PySpark StructType – To rename a nested column in Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c1c87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T12:00:59.844401Z",
     "start_time": "2023-11-29T12:00:59.835408Z"
    }
   },
   "outputs": [],
   "source": [
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6069267b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T12:03:33.940185Z",
     "start_time": "2023-11-29T12:03:33.491520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"name\").cast(schema2),\n",
    "          col(\"dob\"),col(\"gender\"),col(\"salary\")\n",
    "         ).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe7c2b",
   "metadata": {},
   "source": [
    "# 4. Using Select – To rename nested elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936a8676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T12:08:29.701554Z",
     "start_time": "2023-11-29T12:08:29.615606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import * \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "         col(\"name.lastname\").alias(\"lname\"),\n",
    "         col(\"name.middlename\"),\n",
    "         col(\"dob\"),\n",
    "         col(\"gender\"),\n",
    "         col(\"salary\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2093ff0",
   "metadata": {},
   "source": [
    "# 5. Using PySpark DataFrame withColumn – To rename nested columns\n",
    "\n",
    "When you have nested columns on PySpark DatFrame and if you want to rename it, use withColumn on a data frame object to create a new column from an existing and we will need to drop the existing column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3d568e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T12:15:21.564289Z",
     "start_time": "2023-11-29T12:15:21.285181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4=df.withColumn(\"fname\",col(\"name.firstname\"))\\\n",
    "    .withColumn(\"lname\",col(\"name.lastname\"))\\\n",
    "    .withColumn(\"mname\",col(\"name.middlename\"))\\\n",
    "    .drop(\"name\").printSchema()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbd8d4",
   "metadata": {},
   "source": [
    "# 6. Using toDF() – To change all columns in a PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eba1c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T12:19:21.869411Z",
     "start_time": "2023-11-29T12:19:21.764151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- new_col1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- new_col2: string (nullable = true)\n",
      " |-- new_col3: string (nullable = true)\n",
      " |-- new_col4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newColumns=[\"new_col1\",\"new_col2\",\"new_col3\",\"new_col4\"]\n",
    "df.toDF(*newColumns).printSchema()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
