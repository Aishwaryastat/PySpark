{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c75d97",
   "metadata": {},
   "source": [
    "Pyspark StructType & StructField classes are used to progammatically specify the schema to dataframe and create complex columns like nested struct, array, and map columns.\n",
    "\n",
    "StructType is collection of StructField objects that defines column name, column data type, boolean to specify if the field can be nullable or not and metada\n",
    "\n",
    "Dataframe Schemas: `StructType` is commonly used to define the schema when creating a DF, particularly for structured data with fields of different data types. \n",
    "\n",
    "Nested Structures: create a complex schemas with nested structures by nesting `StructType` within other `StructType` objects, alowing you to represent hierarchical or multi level data. \n",
    "\n",
    "Enforcing Data Structure: When reading data from various sources, specifying a `StructType` as the schema ensure that the data is correctly interpreted and structured. This is important when dealing with semi-structured or schema-less data sources. \n",
    "\n",
    "\n",
    "1. StructType - Defines the structure of the dataframe\n",
    "2. StructField- Defines the metadata of the Dataframe column\n",
    "3. Using PySpark StructType and StructField with Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba591b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T15:13:28.415563Z",
     "start_time": "2023-11-27T15:12:12.104730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType\n",
    "\n",
    "spark= SparkSession.builder.appName('type_and_field').getOrCreate()\n",
    "data=[(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "     (\"Michel\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "     (\"Robert\",\"\",\"Williams\",\"45114\",\"M\",4000),\n",
    "     (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "     (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "\n",
    "schema=StructType([\n",
    "    StructField(\"firstname\",StringType(),True),\n",
    "    StructField(\"middlename\",StringType(),True),\n",
    "    StructField(\"lastname\",StringType(),True),\n",
    "    StructField(\"id\",StringType(),True),\n",
    "    StructField(\"gender\",StringType(),True),\n",
    "    StructField(\"salary\",IntegerType(),True)\n",
    "])\n",
    "\n",
    "df=spark.createDataFrame(data=data, schema=schema)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0840fa58",
   "metadata": {},
   "source": [
    "4. Defining Nested StructType object struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af645f95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:24:17.364174Z",
     "start_time": "2023-11-27T14:24:17.253181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining schema using nested StructType\n",
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "\n",
    "structureSchema=StructType([\n",
    "    StructField('name',StructType([\n",
    "        StructField('firstname',StringType(),True),\n",
    "        StructField('middlename',StringType(),True),\n",
    "        StructField('lastname',StringType(),True)\n",
    "    ])),\n",
    "    StructField('id',StringType(),True),\n",
    "    StructField('gender',StringType(),True),\n",
    "    StructField(\"salary\",IntegerType(),True)\n",
    "])\n",
    "df2 = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310ca28",
   "metadata": {},
   "source": [
    "5. Adding & Changing struct of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74f4973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:41:18.828282Z",
     "start_time": "2023-11-27T14:41:17.887052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- OtherInfo: struct (nullable = false)\n",
      " |    |-- identifier: string (nullable = true)\n",
      " |    |-- gender: string (nullable = true)\n",
      " |    |-- salary: integer (nullable = true)\n",
      " |    |-- Salary_Grade: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Updating existing structtype using struct\n",
    "from pyspark.sql.functions import col,struct,when\n",
    "updateddf=df2.withColumn(\"OtherInfo\",\n",
    "                        struct(col(\"id\").alias(\"identifier\"),\n",
    "                              col(\"gender\").alias(\"gender\"),\n",
    "                              col(\"salary\").alias(\"salary\"),\n",
    "                              when(col(\"salary\").cast(IntegerType())<2000,\"Low\")\n",
    "                               .when(col(\"salary\").cast(IntegerType())<4000,\"Medium\")\n",
    "                               .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "                              )).drop(\"id\",\"gender\",\"salary\")\n",
    "\n",
    "updateddf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150f0ed",
   "metadata": {},
   "source": [
    "6. Using SQL ArrayType and MapType\n",
    "\n",
    "SQL StructType also supports `ArrayType` and `MapType` to define the DataFrame columns for array and map collections respectively. On the below example, column hobbies defined as `ArrayType`(StringType) and properties defined as `MapType`(StringType,StringType) meaning both key and value as String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "712801d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-27T14:51:13.799493Z",
     "start_time": "2023-11-27T14:51:13.776506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StructType([StructField('firstname', StringType(), True), StructField('middlename', StringType(), True), StructField('lastname', StringType(), True)]), True), StructField('hobbies', ArrayType(StringType(), True), True), StructField('properties', MapType(StringType(), StringType(), True), True)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using SQL ArrayType & MapType\n",
    "from pyspark.sql.types import ArrayType,MapType\n",
    "ArrayStructureSchema = StructType([\n",
    "    StructField('name',StructType([\n",
    "        StructField(\"firstname\",StringType(),True),\n",
    "        StructField(\"middlename\",StringType(),True),\n",
    "        StructField(\"lastname\",StringType(),True)\n",
    "    ])),\n",
    "    StructField('hobbies',ArrayType(StringType()),True),\n",
    "    StructField(\"properties\",MapType(StringType(),StringType()),True)\n",
    "])\n",
    "ArrayStructureSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb7b7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35edd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
