{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6635b69f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:06:06.895091Z",
     "start_time": "2023-11-30T09:06:06.859109Z"
    }
   },
   "source": [
    "# PySpark Distinct to Drop Duplicate Rows\n",
    "            by Aishwarya Raut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a55a0",
   "metadata": {},
   "source": [
    "PySpark `distinct()` function is used to drop/remove the duplicate rows(all columns) from DF and `dropDuplicates()` is used to drop rows based on selected (one or multiple) columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16e84f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:10:54.213299Z",
     "start_time": "2023-11-30T09:09:47.610968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import PySpark \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "# create SparkSession \n",
    "spark= SparkSession.builder.appName(\"PySpark\").getOrCreate()\n",
    "\n",
    "# prepare data\n",
    "data = [(\"James\", \"Sales\", 3000), \\\n",
    "    (\"Michael\", \"Sales\", 4600), \\\n",
    "    (\"Robert\", \"Sales\", 4100), \\\n",
    "    (\"Maria\", \"Finance\", 3000), \\\n",
    "    (\"James\", \"Sales\", 3000), \\\n",
    "    (\"Scott\", \"Finance\", 3300), \\\n",
    "    (\"Jen\", \"Finance\", 3900), \\\n",
    "    (\"Jeff\", \"Marketing\", 3000), \\\n",
    "    (\"Kumar\", \"Marketing\", 2000), \\\n",
    "    (\"Saif\", \"Sales\", 4100) \\\n",
    "  ]\n",
    "\n",
    "# create Dataframe \n",
    "columns=[\"emp_name\",\"department\",\"salary\"]\n",
    "df=spark.createDataFrame(data,schema=columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cfb0bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:14:52.981064Z",
     "start_time": "2023-11-30T09:14:52.975069Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d7e4db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:46:49.948472Z",
     "start_time": "2023-11-30T09:46:39.413145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|Row|      Day|Day_Of_Week|      Date|Page_Loads|Unique_Visits|First_Time_Visits|Returning_Visits|\n",
      "+---+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|  1|   Sunday|          1| 9/14/2014|      2146|         1582|             1430|             152|\n",
      "|  2|   Monday|          2| 9/15/2014|      3621|         2528|             2297|             231|\n",
      "|  3|  Tuesday|          3| 9/16/2014|      3698|         2630|             2352|             278|\n",
      "|  4|Wednesday|          4| 9/17/2014|      3667|         2614|             2327|             287|\n",
      "|  5| Thursday|          5| 9/18/2014|      3316|         2366|             2130|             236|\n",
      "|  6|   Friday|          6| 9/19/2014|      2815|         1863|             1622|             241|\n",
      "|  7| Saturday|          7| 9/20/2014|      1658|         1118|              985|             133|\n",
      "|  8|   Sunday|          1| 9/21/2014|      2288|         1656|             1481|             175|\n",
      "|  9|   Monday|          2| 9/22/2014|      3638|         2586|             2312|             274|\n",
      "| 10|  Tuesday|          3| 9/23/2014|      4462|         3257|             2989|             268|\n",
      "| 11|Wednesday|          4| 9/24/2014|      4414|         3175|             2891|             284|\n",
      "| 12| Thursday|          5| 9/25/2014|      4315|         3029|             2743|             286|\n",
      "| 13|   Friday|          6| 9/26/2014|      3323|         2249|             2033|             216|\n",
      "| 14| Saturday|          7| 9/27/2014|      1656|         1180|             1040|             140|\n",
      "| 15|   Sunday|          1| 9/28/2014|      2465|         1806|             1613|             193|\n",
      "| 16|   Monday|          2| 9/29/2014|      4096|         2873|             2577|             296|\n",
      "| 17|  Tuesday|          3| 9/30/2014|      4474|         3032|             2720|             312|\n",
      "| 18|Wednesday|          4|10-01-2014|      4124|         2849|             2541|             308|\n",
      "| 19| Thursday|          5|10-02-2014|      3514|         2489|             2239|             250|\n",
      "| 20|   Friday|          6|10-03-2014|      3005|         2097|             1856|             241|\n",
      "+---+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read csv file\n",
    "file_path = \"C:\\\\Users\\\\pcc\\\\Desktop\\\\daily-website-visitors.csv\"\n",
    "df=spark.read.csv(file_path,header=True,inferSchema=True)\n",
    "\n",
    "df=df.withColumnsRenamed({\"Day.Of.Week\":\"Day_Of_Week\",\"Page.Loads\":\"Page_Loads\",\n",
    "                          \"Unique.Visits\":\"Unique_Visits\",\"First.Time.Visits\":\"First_Time_Visits\",\n",
    "                          \"Returning.Visits\":\"Returning_Visits\"})\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a0a023",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:47:41.037745Z",
     "start_time": "2023-11-30T09:47:40.540090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2167"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fcd4bc",
   "metadata": {},
   "source": [
    "# 1. Get Distinct Rows(By comparing All Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f3280fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:47:20.752368Z",
     "start_time": "2023-11-30T09:47:14.346076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distict Count: 2167\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|Row |Day      |Day_Of_Week|Date      |Page_Loads|Unique_Visits|First_Time_Visits|Returning_Visits|\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|294 |Saturday |7          |07-04-2015|1602      |1104         |900              |204             |\n",
      "|721 |Saturday |7          |09-03-2016|1966      |1376         |1101             |275             |\n",
      "|1180|Wednesday|4          |12-06-2017|4595      |3452         |2766             |686             |\n",
      "|1333|Tuesday  |3          |05-08-2018|6702      |4577         |3700             |877             |\n",
      "|1420|Friday   |6          |08-03-2018|3405      |2345         |1833             |512             |\n",
      "|1550|Tuesday  |3          |12-11-2018|7659      |5267         |4330             |937             |\n",
      "|1942|Tuesday  |3          |01-07-2020|3760      |2915         |2492             |423             |\n",
      "|190 |Sunday   |1          |3/22/2015 |3791      |2786         |2388             |398             |\n",
      "|246 |Sunday   |1          |5/17/2015 |3336      |2376         |1988             |388             |\n",
      "|359 |Monday   |2          |09-07-2015|3330      |2354         |1963             |391             |\n",
      "|446 |Thursday |5          |12-03-2015|6160      |4584         |3835             |749             |\n",
      "|535 |Tuesday  |3          |03-01-2016|6214      |4474         |3731             |743             |\n",
      "|621 |Thursday |5          |5/26/2016 |5652      |4119         |3385             |734             |\n",
      "|912 |Monday   |2          |3/13/2017 |4746      |3367         |2721             |646             |\n",
      "|1173|Wednesday|4          |11/29/2017|4555      |3484         |2824             |660             |\n",
      "|1237|Thursday |5          |02-01-2018|4723      |3164         |2571             |593             |\n",
      "|1875|Friday   |6          |11-01-2019|4054      |3010         |2604             |406             |\n",
      "|2061|Tuesday  |3          |05-05-2020|6361      |4900         |4169             |731             |\n",
      "|2090|Wednesday|4          |06-03-2020|4994      |3869         |3239             |630             |\n",
      "|54  |Thursday |5          |11-06-2014|4178      |3034         |2627             |407             |\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distictDF= df.distinct()\n",
    "print(\"Distict Count: \"+str(distictDF.count()))\n",
    "distictDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5690dfb",
   "metadata": {},
   "source": [
    "`distict()` function on DataFrame returns a new DataFrame after removing the duplicate records. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7541e",
   "metadata": {},
   "source": [
    "Alternatively, use `dropDuplicates()` function which return a new dataframe after removing duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86d209e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:47:51.712629Z",
     "start_time": "2023-11-30T09:47:48.064363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count: 2167\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|Row |Day      |Day_Of_Week|Date      |Page_Loads|Unique_Visits|First_Time_Visits|Returning_Visits|\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "|294 |Saturday |7          |07-04-2015|1602      |1104         |900              |204             |\n",
      "|721 |Saturday |7          |09-03-2016|1966      |1376         |1101             |275             |\n",
      "|1180|Wednesday|4          |12-06-2017|4595      |3452         |2766             |686             |\n",
      "|1333|Tuesday  |3          |05-08-2018|6702      |4577         |3700             |877             |\n",
      "|1420|Friday   |6          |08-03-2018|3405      |2345         |1833             |512             |\n",
      "|1550|Tuesday  |3          |12-11-2018|7659      |5267         |4330             |937             |\n",
      "|1942|Tuesday  |3          |01-07-2020|3760      |2915         |2492             |423             |\n",
      "|190 |Sunday   |1          |3/22/2015 |3791      |2786         |2388             |398             |\n",
      "|246 |Sunday   |1          |5/17/2015 |3336      |2376         |1988             |388             |\n",
      "|359 |Monday   |2          |09-07-2015|3330      |2354         |1963             |391             |\n",
      "|446 |Thursday |5          |12-03-2015|6160      |4584         |3835             |749             |\n",
      "|535 |Tuesday  |3          |03-01-2016|6214      |4474         |3731             |743             |\n",
      "|621 |Thursday |5          |5/26/2016 |5652      |4119         |3385             |734             |\n",
      "|912 |Monday   |2          |3/13/2017 |4746      |3367         |2721             |646             |\n",
      "|1173|Wednesday|4          |11/29/2017|4555      |3484         |2824             |660             |\n",
      "|1237|Thursday |5          |02-01-2018|4723      |3164         |2571             |593             |\n",
      "|1875|Friday   |6          |11-01-2019|4054      |3010         |2604             |406             |\n",
      "|2061|Tuesday  |3          |05-05-2020|6361      |4900         |4169             |731             |\n",
      "|2090|Wednesday|4          |06-03-2020|4994      |3869         |3239             |630             |\n",
      "|54  |Thursday |5          |11-06-2014|4178      |3034         |2627             |407             |\n",
      "+----+---------+-----------+----------+----------+-------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.dropDuplicates()\n",
    "print(\"Distinct count: \"+str(df2.count()))\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128644c",
   "metadata": {},
   "source": [
    "# 2. PySpark Distinct of Selected Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e076d75c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T09:48:20.296909Z",
     "start_time": "2023-11-30T09:48:16.629224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct count of department & salary : 7\n",
      "+---+---------+-----------+---------+----------+-------------+-----------------+----------------+\n",
      "|Row|Day      |Day_Of_Week|Date     |Page_Loads|Unique_Visits|First_Time_Visits|Returning_Visits|\n",
      "+---+---------+-----------+---------+----------+-------------+-----------------+----------------+\n",
      "|6  |Friday   |6          |9/19/2014|2815      |1863         |1622             |241             |\n",
      "|2  |Monday   |2          |9/15/2014|3621      |2528         |2297             |231             |\n",
      "|7  |Saturday |7          |9/20/2014|1658      |1118         |985              |133             |\n",
      "|1  |Sunday   |1          |9/14/2014|2146      |1582         |1430             |152             |\n",
      "|5  |Thursday |5          |9/18/2014|3316      |2366         |2130             |236             |\n",
      "|3  |Tuesday  |3          |9/16/2014|3698      |2630         |2352             |278             |\n",
      "|4  |Wednesday|4          |9/17/2014|3667      |2614         |2327             |287             |\n",
      "+---+---------+-----------+---------+----------+-------------+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropDistictDF= df.dropDuplicates([\"Day\",\"Day_Of_Week\"])\n",
    "print(\"Distinct count of department & salary : \"+str(dropDistictDF.count()))\n",
    "dropDistictDF.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
