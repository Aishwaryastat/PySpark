{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c869e2",
   "metadata": {},
   "source": [
    "# PySpark `withColumn()` usage by \n",
    "                            Aishwarya Raut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd50e7",
   "metadata": {},
   "source": [
    "PySpark `withColumn()` is a transformation function of DataFrame which is used to change the value, convert the datatype of an existing column, create a new column, and many more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c419028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T10:55:31.021688Z",
     "start_time": "2023-11-29T10:54:38.825740Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SP').getOrCreate()\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35b22f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:02:47.066613Z",
     "start_time": "2023-11-29T11:02:47.033631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbac9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:03:21.911563Z",
     "start_time": "2023-11-29T11:03:21.866594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Change DataType \n",
    "from pyspark.sql.functions import col\n",
    "a=df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\"))\n",
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3aaba",
   "metadata": {},
   "source": [
    "# 2. Update The Value of an Existing Column\n",
    "\n",
    "PySpark withColumn() function of DataFrame can also be used to change the value of an existing column. In order to change the value, pass an existing column name as a first argument and a value to be assigned as a second argument to the withColumn() function. Note that the second argument should be Column type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e855f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:06:21.660055Z",
     "start_time": "2023-11-29T11:06:21.266186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstname: string, middlename: string, lastname: string, dob: string, gender: string, salary: bigint]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumn(\"salary\",col(\"salary\")*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3172773a",
   "metadata": {},
   "source": [
    "# 3. Create a Column from an Existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43385c01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:13:42.124293Z",
     "start_time": "2023-11-29T11:13:42.054334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- new_column: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=df.withColumn(\"new_column\",col(\"salary\")*-1)\n",
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f00011d",
   "metadata": {},
   "source": [
    "# 4. Add a New Column using withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.withColumn(\"Country\",lit(\"USA\")).show()\n",
    "\n",
    "df.withColumn(\"country\",lit(\"USA\"))\n",
    "    .withColumn(\"anotherColumn\",lit(\"anothervalue\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459fb8c",
   "metadata": {},
   "source": [
    "# 5. Rename Column Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda73c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:33:40.555600Z",
     "start_time": "2023-11-29T11:33:40.503623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=df.withColumnRenamed(\"gender\",\"sex\")\n",
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e786db9",
   "metadata": {},
   "source": [
    "# 6. Drop Column From PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74c3500b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T11:37:14.805642Z",
     "start_time": "2023-11-29T11:37:14.754673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a=df.drop(\"salary\")\n",
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b014e",
   "metadata": {},
   "source": [
    "Note: Note that all of these functions return the new DataFrame after applying the functions instead of updating DataFrame."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
